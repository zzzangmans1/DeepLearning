# 21장 설명 가능한 딥러닝 모델 만들기

딥러닝으로 알츠하이머형 치매 여부를 판단하는 실험은 상당히 높은 정확도를 보입니다.
치매에 걸릴 확률이 몇 년 후에 몇 퍼센트인지까지도 에측하기도 하지요.
그런데 이렇게 만든 모델을 실제 의료 현장에서 사용하는 것은 쉽지 않습니다.
꼭 필요한 단계가 있기 때문입니다.
왜 그런 결과가 나왔는지 설명해 주는 단계입니다.
자신의 건강과 생명에 관한 일인데, '그냥 딥러닝이 그러더군요'라는 설명을 듣고 싶은 환자는 없을 테지요.

그런데 딥러닝이 왜 그런 판단을 했는지 설명하는 것은 어렵습니다.
다차원 입력으로 인한 계산의 복잡성, 드러나지 않는 은닉층  등 그 중간 과정을 유추해 내기 어렵게 만드는 여러가지 요소가 있기 때문이지요.
만일 딥러닝이 왜 그런 예측과 판단을 했는지, 그 정확한 근거를 알 수 있다면 환자나 사용자들에게 설명할 수 있을 뿐 아니라, 더 나은 모델을 만들고 더 좋은 데이터를 전부하는 데 도움이 많이 될 것입니다.

## 1 딥러닝의 결과를 설명하는 방법

설명이 가능한 딥러닝을 **XAI**(Explainable AI)라고도 합니다.
예측의 근거를 설명해 주는 기술이지요.
이미지를 사용해 이름이나 물건의 종류를 맞히는 모델을 만들었다면, 이미지의 어디를 보고 왜 그런 판단을 했는지 설명해 내는 또 다른 그림을 그려내는 것입니다.

현재 널리 사용되는 것은 크게 두 가지입니다.
첫째는 딥러닝의 중간 과정에서 나온 특징 맵을 이용하는 방법입니다.
이러한 방법의 대표적인 사례가 **CAM**(Class Activation Map)입니다.

CAM의 원리를 살펴보기 위해 컨볼루션 신경망(CNN)에 대해 조금 더 생각해 보겠습니다.
데이터가 입력되면 컨볼루션 레이어, 풀링 레이어에 통과시키는 것이 컨볼루션 신경망이라고 배웠지요.
그런데 이러한 레이어들을 통과시키는 이유가 뭘까요? 신경망 하습을 위해서 입력된 2D 이미지들을 1차원 배열로 축소해야 하기 때문입니다.
차원을 줄이는 과정에서 공간 정보의 손실이 발생할 수밖에 없고, 이를 해소하기 위해 컨볼루션 신경망이 만들어진 것입니다.
이를 바꾸어 말하면, 컨볼루션 신경망 내부의 레이어들을 하나씩 거쳐 마지막 예측을 위한 단계까지 온 데이터들(이를 중간 맵이라고 함)은 입력 데이터의 속성을 잘 간직하고 있다는 의미가 됩니다.

CAM은 여기서 아이디어를 얻었습니다.
이 데이터를 1차원으로 축소시키는 Flatten 단계 직전에 개입해서 그때까지 만들어진 중간 맵들을 따로 모읍니다(1).
그리고 그 중간 맵들 각각으로부터 평균값(Global Max Pooling, GAP)(중간 맵 안에 들어 있는 모든 값의 평균)을 뽑은 후(2), 이 평균값과 최종 예측 사이에서 한 번 더 학습합니다(3).
그러면 어떤 중간 맵이 최종 결정에 큰 역할을 하는지 알려 주는 가중치(4)를 얻게 되겠지요.
이 가중치를 각 중간맵에 곱해 중요한 중간 맵은 가중하고 불필요한 중간 맵은 자연스럽게 없애면서 특징 맵(5)을 만들어 내는 것이 바로 CAM입니다.
같은 원리이지만, 평균값을 계산하기 위해 모델의 구조를 바꾸어야 하는 번거로움을 피하고자 평균값 대신 기울기를 이용하는 방법도 개발되었습니다.
이를 그레이디언트 **CAM**(Gradient CAM)이라고 합니다.


## 2 설명 가능한 딥러닝의 실행

이제 CAM과 폐쇄성 민감도 방식을 어떻게 실행할 수 있는지 알아보겠습니다.
실습을 위해 설명 가능한 딥러닝 방식을 구현하게 해 주는 tf-explain 라이브러리와 이를 돕는 OpenCV 라이브러리가 필요합니다.
코랩에서는 OpenCV 라이브러리를 기본으로 제공하므로 tf-explain 라이브러리만 설치합니다.

``` python
!pip install tf-explain
```

설치 후 다음과 같이 우리가 실행하고자 하는 Gradient CAM, 폐쇄성 민감도 방식 함수를 불러옵니다.

``` python
from tf_explain.core.grad_cam import GradCAM
from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity
```

앞서 다룬 바 있는 imagenet 학습 모델을 다시 한 번 불러와 우리의 모델로 사용하겠습니다.

``` python
model = VGG16(weight="imagenet", include_top=True)
```

이제 그레이디언트 CAM을 실행하는 방법은 다음과 같습니다.

``` python
explainer = GradCAM() # 그레이디언트 CAM 알고리즘 선택
output = explainer.explain(데이터, 모델, 클래스) # 그레이디언트 CAM 실행
explainer.save(output, 저장될 폴더, 저장될 이름) # 실행 후 저장될 위치와 이름
```

먼저 GradCAM() 함수를 explainer 인스턴스에 할당했습니다.
이 안에는 XAI를 실행하는 explain() 함수와 이를 저장하는 save() 함수가 있습니다.
explain() 함수 안에는 데이터, 모델, 이미지넷의 클래스 번호가 들어갑니다. 
save() 함수 안에는 XAI를 실행한 결과, 저장될 폴더, 그리고 저장될 이름이 들어갑니다.

오클루전 방식은 다음과 같습니다.

``` python
explainer = OcclusionSensitivity() # 오클루전 알고리즘 선택
# 패치 크기 설정이 추가됨
output = explainer.explain(데이터, 모델, 클래스, 패치 크기)
explainer.save(output, 저장될 폴더, 저장될 이름)
```

여기서 달라진 점은 explain() 함수 안의 인자로 패치 크기가 들어간다는 것입니다.
패치 크기란 사진을 가리며 움직이는 검은색 사각형의 크기를 의미합니다.
이를 크게 잡으면 조금 더 넓은 범위의 결과가 나오고, 작게 잡으면 조금 더 세밀한 부분을 가리키는 결과가 나옵니다.

[실습1 설명 가능한 딥러닝](https://github.com/zzzangmans1/DeepLearning/blob/main/21/21.py)

![image](https://user-images.githubusercontent.com/52357235/179480728-21bc3593-2e05-4478-a458-abc5f419d6c3.png)

이 코드에서 patch_size = 40 부분을 다른 크기로 조절하면 결과가 조금씩 달라집니다.
