# 18장 시퀀스 배열로 다루는 순환 신경망(RNN)

인공지능이 문장을 듣고 이해한다는 것은 많은 문장을 '이미 학습(train)해 놓았다'는 것입니다.
그런데 문장을 학습하는 것은 우리가 지금까지 공부한 내용과는 성질이 조금 다릅니다.
문장은 여러 개의 단어로 이루어져 있는데, 그 의미를 전달하려면 각 단어가 정해진 순서대로 입력되어야 하기 때문입니다.
즉, 여러 데이터가 순서와 관계없이 입력되던 것과는 다르게, 이번에는 과거에 입력된 데이터와 나중에 입력된 사이의 관계를 고려해야 하는 문제가 생기는 것입니다.
이를 해결하기 위해 **순환 신경망**(Recurrent Neural Network, RNN) 방법이 고안되었습니다.
순환 신경망은 여러 개의 데이터가 순서대로 입력되었을 때 앞서 입력받은 데이터를 잠시 기억해 놓는 방법입니다.
그리고 기억된 데이터가 얼마나 중요한지 판단하고 별도의 가중치를 주어 다음 데이터로 넘어갑니다.
모든 입력 값에 이 작업을 순서대로 실행하므로 다음 층으로 넘어가기 전에 같은 층을 맴도는 것처럼 보입니다.
이렇게 같은 층 안에서 맵도는 성질 때문에 순환 신경망(이하 RNN)이라고 합니다.

![image](https://user-images.githubusercontent.com/52357235/178678101-f7dc3a88-bebe-42cb-bf45-da3ecd898a47.png)

RNN이 처음 개발된 이후, RNN의 결과를 더욱 개선하기 위한 노력이 계속되어 왔습니다.
이 중에서 LSTM(Long Short Term Memory) 방법을 함께 사용하는 기법이 현재 가장 널리 사용되고 있습니다.
LSTM은 한 층 안에서 반복을 많이 해야 하는 RNN의 특성상 일반 신경망보다 기울기 소실문제가 더 많이 발생하고 이를 해결하기 어렵다는 단점을 보완한 방법입니다.
즉, 반복되기 직전에 다음 층으로 기억된 값을 넘길지 여부를 관리하는 단계를 하나 더 추가하는 것입니다.

RNN 방식의 장점은 입력 값과 출력 값을 어떻게 설정하느냐에 따라 여러 가지 상황에서 이를 적용할 수 있다는 것입니다.

- 다수 입력 단일 출력
문장을 읽고 뜻을 파악할 때 활용
- 단일 입력 다수 출력
사진의 캡션을 만들 때 활용
- 다수 입력 다수 출력
문장을 번역할 때 활용

케라스는 딥러닝 학습에 필요한 데이터를 쉽게 내려받을 수 있게 load_data() 함수를 제공합니다.
앞서 살펴본 MNIST 데이터셋 외에도 RNN 학습에 적절한 텍스트 대용량 데이터를 제공합니다.
케라스가 제공하는 '로이터 뉴스 카테고리 분류'와 IMDB 영화 리뷰'를 통해 지금부터 RNN을 학습해 보겠습니다.

